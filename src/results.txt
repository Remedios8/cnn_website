_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
conv2d_1 (Conv2D)            (None, 32, 32, 32)        320
_________________________________________________________________
batch_normalization_1 (Batch (None, 32, 32, 32)        128
_________________________________________________________________
activation_1 (Activation)    (None, 32, 32, 32)        0
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 32, 32, 32)        9248
_________________________________________________________________
batch_normalization_2 (Batch (None, 32, 32, 32)        128
_________________________________________________________________
activation_2 (Activation)    (None, 32, 32, 32)        0
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0
_________________________________________________________________
dropout_1 (Dropout)          (None, 16, 16, 32)        0
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 16, 16, 64)        18496
_________________________________________________________________
batch_normalization_3 (Batch (None, 16, 16, 64)        256
_________________________________________________________________
activation_3 (Activation)    (None, 16, 16, 64)        0
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 14, 14, 64)        36928
_________________________________________________________________
batch_normalization_4 (Batch (None, 14, 14, 64)        256
_________________________________________________________________
activation_4 (Activation)    (None, 14, 14, 64)        0
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 7, 7, 64)          0
_________________________________________________________________
dropout_2 (Dropout)          (None, 7, 7, 64)          0
_________________________________________________________________
flatten_1 (Flatten)          (None, 3136)              0
_________________________________________________________________
dense_1 (Dense)              (None, 256)               803072
_________________________________________________________________
batch_normalization_5 (Batch (None, 256)               1024
_________________________________________________________________
activation_5 (Activation)    (None, 256)               0
_________________________________________________________________
dropout_3 (Dropout)          (None, 256)               0
_________________________________________________________________
dense_2 (Dense)              (None, 72)                18504
_________________________________________________________________
batch_normalization_6 (Batch (None, 72)                288
_________________________________________________________________
activation_6 (Activation)    (None, 72)                0
=================================================================
Total params: 888,648
Trainable params: 887,608
Non-trainable params: 1,040
_________________________________________________________________
None
Train on 8294 samples, validate on 922 samples
Epoch 1/50
 - 198s - loss: 3.1920 - acc: 0.2103 - val_loss: 2.2080 - val_acc: 0.5271
Epoch 2/50
 - 199s - loss: 2.1070 - acc: 0.4431 - val_loss: 0.8207 - val_acc: 0.8167
Epoch 3/50
 - 197s - loss: 1.6133 - acc: 0.5562 - val_loss: 0.5070 - val_acc: 0.8829
Epoch 4/50
 - 202s - loss: 1.3268 - acc: 0.6186 - val_loss: 0.3876 - val_acc: 0.9056
Epoch 5/50
 - 216s - loss: 1.1295 - acc: 0.6835 - val_loss: 0.2776 - val_acc: 0.9306
Epoch 6/50
 - 183s - loss: 0.9955 - acc: 0.7143 - val_loss: 0.2204 - val_acc: 0.9382
Epoch 7/50
 - 185s - loss: 0.8474 - acc: 0.7669 - val_loss: 0.1666 - val_acc: 0.9610
Epoch 8/50
 - 205s - loss: 0.7524 - acc: 0.7990 - val_loss: 0.1296 - val_acc: 0.9729
Epoch 9/50
 - 215s - loss: 0.6779 - acc: 0.8206 - val_loss: 0.1218 - val_acc: 0.9783
Epoch 10/50
 - 208s - loss: 0.5988 - acc: 0.8451 - val_loss: 0.1148 - val_acc: 0.9751
Epoch 11/50
 - 208s - loss: 0.5393 - acc: 0.8618 - val_loss: 0.1369 - val_acc: 0.9664
Epoch 12/50
 - 211s - loss: 0.5111 - acc: 0.8646 - val_loss: 0.0852 - val_acc: 0.9848
Epoch 13/50
 - 215s - loss: 0.4778 - acc: 0.8774 - val_loss: 0.0741 - val_acc: 0.9805
Epoch 14/50
 - 203s - loss: 0.4354 - acc: 0.8896 - val_loss: 0.0688 - val_acc: 0.9826
Epoch 15/50
 - 240s - loss: 0.4096 - acc: 0.8985 - val_loss: 0.0617 - val_acc: 0.9837
Epoch 16/50
 - 244s - loss: 0.3786 - acc: 0.9043 - val_loss: 0.0764 - val_acc: 0.9826
Epoch 17/50
 - 290s - loss: 0.3671 - acc: 0.9075 - val_loss: 0.0555 - val_acc: 0.9881
Epoch 18/50
 - 254s - loss: 0.3352 - acc: 0.9190 - val_loss: 0.0421 - val_acc: 0.9913
Epoch 19/50
 - 316s - loss: 0.3220 - acc: 0.9174 - val_loss: 0.0448 - val_acc: 0.9881
Epoch 20/50
 - 225s - loss: 0.3164 - acc: 0.9181 - val_loss: 0.0431 - val_acc: 0.9881
Epoch 21/50
 - 247s - loss: 0.3050 - acc: 0.9239 - val_loss: 0.0448 - val_acc: 0.9892
Epoch 22/50
 - 216s - loss: 0.3000 - acc: 0.9260 - val_loss: 0.0401 - val_acc: 0.9892
Epoch 23/50
 - 228s - loss: 0.2671 - acc: 0.9322 - val_loss: 0.0392 - val_acc: 0.9859
Epoch 24/50
 - 201s - loss: 0.2638 - acc: 0.9350 - val_loss: 0.0380 - val_acc: 0.9913
Epoch 25/50
 - 189s - loss: 0.2566 - acc: 0.9343 - val_loss: 0.0399 - val_acc: 0.9870
Epoch 26/50
 - 239s - loss: 0.2450 - acc: 0.9409 - val_loss: 0.0351 - val_acc: 0.9881
Epoch 27/50
 - 255s - loss: 0.2345 - acc: 0.9391 - val_loss: 0.0387 - val_acc: 0.9870
Epoch 28/50
 - 271s - loss: 0.2451 - acc: 0.9406 - val_loss: 0.0379 - val_acc: 0.9881
Epoch 29/50
 - 260s - loss: 0.2334 - acc: 0.9424 - val_loss: 0.0336 - val_acc: 0.9913
Epoch 30/50
 - 260s - loss: 0.2235 - acc: 0.9439 - val_loss: 0.0289 - val_acc: 0.9946
Epoch 31/50
 - 261s - loss: 0.2140 - acc: 0.9485 - val_loss: 0.0332 - val_acc: 0.9870
Epoch 32/50
 - 261s - loss: 0.2022 - acc: 0.9483 - val_loss: 0.0275 - val_acc: 0.9902
Epoch 33/50
 - 257s - loss: 0.1994 - acc: 0.9502 - val_loss: 0.0309 - val_acc: 0.9935
Epoch 34/50
 - 238s - loss: 0.2035 - acc: 0.9502 - val_loss: 0.0312 - val_acc: 0.9892
Epoch 35/50
 - 251s - loss: 0.1747 - acc: 0.9596 - val_loss: 0.0230 - val_acc: 0.9957
Epoch 36/50
 - 281s - loss: 0.1909 - acc: 0.9558 - val_loss: 0.0261 - val_acc: 0.9913
Epoch 37/50
 - 335s - loss: 0.1812 - acc: 0.9554 - val_loss: 0.0270 - val_acc: 0.9978
Epoch 38/50
 - 314s - loss: 0.1806 - acc: 0.9526 - val_loss: 0.0228 - val_acc: 0.9946
Epoch 39/50
 - 259s - loss: 0.1730 - acc: 0.9583 - val_loss: 0.0245 - val_acc: 0.9913
Epoch 40/50
 - 211s - loss: 0.1590 - acc: 0.9626 - val_loss: 0.0264 - val_acc: 0.9913
Epoch 41/50
 - 183s - loss: 0.1618 - acc: 0.9600 - val_loss: 0.0237 - val_acc: 0.9957
Epoch 42/50
 - 214s - loss: 0.1630 - acc: 0.9603 - val_loss: 0.0288 - val_acc: 0.9902
Epoch 43/50
 - 309s - loss: 0.1648 - acc: 0.9588 - val_loss: 0.0193 - val_acc: 0.9957
Epoch 44/50
 - 365s - loss: 0.1679 - acc: 0.9561 - val_loss: 0.0257 - val_acc: 0.9924
Epoch 45/50
 - 296s - loss: 0.1514 - acc: 0.9636 - val_loss: 0.0284 - val_acc: 0.9902
Epoch 46/50
 - 212s - loss: 0.1551 - acc: 0.9627 - val_loss: 0.0237 - val_acc: 0.9924
Epoch 47/50
 - 365s - loss: 0.1549 - acc: 0.9649 - val_loss: 0.0216 - val_acc: 0.9957
Epoch 48/50
 - 324s - loss: 0.1503 - acc: 0.9606 - val_loss: 0.0212 - val_acc: 0.9946
Epoch 49/50
 - 357s - loss: 0.1409 - acc: 0.9666 - val_loss: 0.0285 - val_acc: 0.9892
Epoch 50/50
 - 350s - loss: 0.1354 - acc: 0.9676 - val_loss: 0.0242 - val_acc: 0.9935

Test score   : 0.0337
Test accuracy: 0.9926
Сохраняем сеть
Сохранение сети завершено